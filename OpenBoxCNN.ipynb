{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from torchvision import datasets, transforms, utils\n",
    "from src.utility import convert_image_np\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from matplotlib import gridspec\n",
    "from lib.data import Mimic2\n",
    "from lib.utility import show_tensor_image, show_acc, to_var\n",
    "from lib.model import MLP\n",
    "from lib.openbox import open_box, count_config, find_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, criterion, optimizer, print_every=None, epochs=1000, max_time=10):\n",
    "    net.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    # max_time given in seconds\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (x, y) in enumerate(trainloader):\n",
    "            \n",
    "            end = time.time()\n",
    "            if end - start >= max_time:\n",
    "                print('Finished Training in %ds' % (end-start))                \n",
    "                return\n",
    "            \n",
    "            # get the inputs\n",
    "            x, y = to_var(x), to_var(y)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data.item()\n",
    "            if print_every is not None and i % print_every == (print_every-1): \n",
    "                print('[%d, %5d] loss: %.10f' %\n",
    "                      (epoch + 1, i + 1, running_loss / print_every))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training in %ds' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenboxCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, neuron_sizes): # using relu activation\n",
    "        super(MLP, self).__init__()\n",
    "        self.neuron_sizes = neuron_sizes\n",
    "        \n",
    "        layers = []\n",
    "        for s0, s1 in zip(neuron_sizes[:-1], neuron_sizes[1:]):\n",
    "            layers.extend([\n",
    "                nn.Linear(s0, s1),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            ])\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.neuron_sizes[0])\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking if it is exact\n",
      "min: 0.000000, mean: 0.000000, max: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def abs_diff(a, b):\n",
    "    return torch.abs(a - b).sum().data.numpy()\n",
    "\n",
    "def diff_check(net, num_runs=100):\n",
    "    diff = []\n",
    "    d = net.classifier[0].in_features\n",
    "    for i in range(num_runs):\n",
    "        x = to_var(torch.randn(d))\n",
    "        W, b, C = open_box(net, x)\n",
    "        diff.append(abs_diff(torch.mv(W, x) + b, net(x)))\n",
    "    return diff\n",
    "\n",
    "diff = diff_check(MLP([100,50,30,20,10]))\n",
    "sns.distplot(diff, kde=False)\n",
    "print('checking if it is exact')\n",
    "print('min: %f, mean: %f, max: %f' % (np.min(diff), np.mean(diff), np.max(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
